{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
"import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords,words,brown\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from string import punctuation\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout, Conv1D, MaxPooling1D, Activation, Bidirectional\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from keras import layers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras import models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names\\\\Arabic.txt', 'data/names\\\\Chinese.txt', 'data/names\\\\Czech.txt', 'data/names\\\\Dutch.txt', 'data/names\\\\English.txt', 'data/names\\\\French.txt', 'data/names\\\\German.txt', 'data/names\\\\Greek.txt', 'data/names\\\\Irish.txt', 'data/names\\\\Italian.txt', 'data/names\\\\Japanese.txt', 'data/names\\\\Korean.txt', 'data/names\\\\Polish.txt', 'data/names\\\\Portuguese.txt', 'data/names\\\\Russian.txt', 'data/names\\\\Scottish.txt', 'data/names\\\\Spanish.txt', 'data/names\\\\Vietnamese.txt']\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding language names as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_dict = {}\n",
    "i = 1\n",
    "for key in category_lines.keys():\n",
    "    key_dict[key] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 1,\n",
       " 'Chinese': 2,\n",
       " 'Czech': 3,\n",
       " 'Dutch': 4,\n",
       " 'English': 5,\n",
       " 'French': 6,\n",
       " 'German': 7,\n",
       " 'Greek': 8,\n",
       " 'Irish': 9,\n",
       " 'Italian': 10,\n",
       " 'Japanese': 11,\n",
       " 'Korean': 12,\n",
       " 'Polish': 13,\n",
       " 'Portuguese': 14,\n",
       " 'Russian': 15,\n",
       " 'Scottish': 16,\n",
       " 'Spanish': 17,\n",
       " 'Vietnamese': 18}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Arabic, English and Russian name data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These languages have the most data points (>2000 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "languages = []\n",
    "for key, value in category_lines.items():\n",
    "     if key_dict[key] in (1,5,15):\n",
    "        for name in value:\n",
    "            names.append(name)\n",
    "            languages.append(key_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2000, 5: 3668, 15: 9408})"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = names[0:4000]\n",
    "X.extend(names[5668:7668])\n",
    "Y = languages[0:4000]\n",
    "Y.extend(languages[5668:7668])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "tok = Tokenizer(num_words=None, char_level = True)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = pad_sequences(sequences,maxlen=max_len, padding = 'post')\n",
    "train_data = np.array(sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train_data,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tok.word_index)+1, 128, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4080 samples, validate on 1020 samples\n",
      "Epoch 1/45\n",
      "4080/4080 [==============================] - 69s 17ms/step - loss: 1.3447 - categorical_accuracy: 0.5120 - val_loss: 0.6565 - val_categorical_accuracy: 0.7275\n",
      "Epoch 2/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.4631 - categorical_accuracy: 0.8216 - val_loss: 0.3933 - val_categorical_accuracy: 0.8480\n",
      "Epoch 3/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.3159 - categorical_accuracy: 0.8703 - val_loss: 0.2955 - val_categorical_accuracy: 0.8931\n",
      "Epoch 4/45\n",
      "4080/4080 [==============================] - 45s 11ms/step - loss: 0.2914 - categorical_accuracy: 0.8860 - val_loss: 0.2770 - val_categorical_accuracy: 0.8951\n",
      "Epoch 5/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.2693 - categorical_accuracy: 0.8946 - val_loss: 0.2470 - val_categorical_accuracy: 0.9049\n",
      "Epoch 6/45\n",
      "4080/4080 [==============================] - 45s 11ms/step - loss: 0.2630 - categorical_accuracy: 0.8917 - val_loss: 0.2324 - val_categorical_accuracy: 0.9137\n",
      "Epoch 7/45\n",
      "4080/4080 [==============================] - 41s 10ms/step - loss: 0.2402 - categorical_accuracy: 0.9015 - val_loss: 0.2199 - val_categorical_accuracy: 0.9078\n",
      "Epoch 8/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.2335 - categorical_accuracy: 0.9044 - val_loss: 0.2001 - val_categorical_accuracy: 0.9206\n",
      "Epoch 9/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.2219 - categorical_accuracy: 0.9115 - val_loss: 0.2081 - val_categorical_accuracy: 0.9167\n",
      "Epoch 10/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.2029 - categorical_accuracy: 0.9230 - val_loss: 0.1890 - val_categorical_accuracy: 0.9294\n",
      "Epoch 11/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.2048 - categorical_accuracy: 0.9218 - val_loss: 0.1827 - val_categorical_accuracy: 0.9343\n",
      "Epoch 12/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.2054 - categorical_accuracy: 0.9184 - val_loss: 0.1780 - val_categorical_accuracy: 0.9304\n",
      "Epoch 13/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1780 - categorical_accuracy: 0.9319 - val_loss: 0.1783 - val_categorical_accuracy: 0.9304\n",
      "Epoch 14/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1651 - categorical_accuracy: 0.9360 - val_loss: 0.1721 - val_categorical_accuracy: 0.9324\n",
      "Epoch 15/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.1605 - categorical_accuracy: 0.9404 - val_loss: 0.1732 - val_categorical_accuracy: 0.9343\n",
      "Epoch 16/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1556 - categorical_accuracy: 0.9397 - val_loss: 0.1944 - val_categorical_accuracy: 0.9314\n",
      "Epoch 17/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.1497 - categorical_accuracy: 0.9419 - val_loss: 0.1605 - val_categorical_accuracy: 0.9441\n",
      "Epoch 18/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1464 - categorical_accuracy: 0.9429 - val_loss: 0.1602 - val_categorical_accuracy: 0.9382\n",
      "Epoch 19/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1367 - categorical_accuracy: 0.9507 - val_loss: 0.1738 - val_categorical_accuracy: 0.9353\n",
      "Epoch 20/45\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 0.1366 - categorical_accuracy: 0.9490 - val_loss: 0.1490 - val_categorical_accuracy: 0.9471\n",
      "Epoch 21/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1301 - categorical_accuracy: 0.9542 - val_loss: 0.1438 - val_categorical_accuracy: 0.9461\n",
      "Epoch 22/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1218 - categorical_accuracy: 0.9554 - val_loss: 0.1544 - val_categorical_accuracy: 0.9412\n",
      "Epoch 23/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1195 - categorical_accuracy: 0.9561 - val_loss: 0.1506 - val_categorical_accuracy: 0.9441\n",
      "Epoch 24/45\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 0.1158 - categorical_accuracy: 0.9578 - val_loss: 0.1442 - val_categorical_accuracy: 0.9431\n",
      "Epoch 25/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1143 - categorical_accuracy: 0.9564 - val_loss: 0.1323 - val_categorical_accuracy: 0.9451\n",
      "Epoch 26/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.1037 - categorical_accuracy: 0.9620 - val_loss: 0.1465 - val_categorical_accuracy: 0.9431\n",
      "Epoch 27/45\n",
      "4080/4080 [==============================] - 35s 9ms/step - loss: 0.1085 - categorical_accuracy: 0.9586 - val_loss: 0.1288 - val_categorical_accuracy: 0.9480\n",
      "Epoch 28/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0987 - categorical_accuracy: 0.9620 - val_loss: 0.1295 - val_categorical_accuracy: 0.9490\n",
      "Epoch 29/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0997 - categorical_accuracy: 0.9642 - val_loss: 0.1422 - val_categorical_accuracy: 0.9422\n",
      "Epoch 30/45\n",
      "4080/4080 [==============================] - 33s 8ms/step - loss: 0.0943 - categorical_accuracy: 0.9650 - val_loss: 0.1327 - val_categorical_accuracy: 0.9480\n",
      "Epoch 31/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.1023 - categorical_accuracy: 0.9593 - val_loss: 0.1203 - val_categorical_accuracy: 0.9569\n",
      "Epoch 32/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0883 - categorical_accuracy: 0.9691 - val_loss: 0.1289 - val_categorical_accuracy: 0.9510\n",
      "Epoch 33/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0851 - categorical_accuracy: 0.9689 - val_loss: 0.1235 - val_categorical_accuracy: 0.9500\n",
      "Epoch 34/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0900 - categorical_accuracy: 0.9652 - val_loss: 0.1296 - val_categorical_accuracy: 0.9480\n",
      "Epoch 35/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0805 - categorical_accuracy: 0.9696 - val_loss: 0.1153 - val_categorical_accuracy: 0.9559\n",
      "Epoch 36/45\n",
      "4080/4080 [==============================] - 37s 9ms/step - loss: 0.0715 - categorical_accuracy: 0.9723 - val_loss: 0.1222 - val_categorical_accuracy: 0.9559\n",
      "Epoch 37/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.0735 - categorical_accuracy: 0.9713 - val_loss: 0.1245 - val_categorical_accuracy: 0.9520\n",
      "Epoch 38/45\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 0.0799 - categorical_accuracy: 0.9701 - val_loss: 0.1242 - val_categorical_accuracy: 0.9510\n",
      "Epoch 39/45\n",
      "4080/4080 [==============================] - 40s 10ms/step - loss: 0.0714 - categorical_accuracy: 0.9728 - val_loss: 0.1105 - val_categorical_accuracy: 0.9588\n",
      "Epoch 40/45\n",
      "4080/4080 [==============================] - 39s 9ms/step - loss: 0.0646 - categorical_accuracy: 0.9748 - val_loss: 0.1102 - val_categorical_accuracy: 0.9569\n",
      "Epoch 41/45\n",
      "4080/4080 [==============================] - 39s 10ms/step - loss: 0.0609 - categorical_accuracy: 0.9770 - val_loss: 0.1110 - val_categorical_accuracy: 0.9588\n",
      "Epoch 42/45\n",
      "4080/4080 [==============================] - 38s 9ms/step - loss: 0.0592 - categorical_accuracy: 0.9784 - val_loss: 0.1176 - val_categorical_accuracy: 0.9549\n",
      "Epoch 43/45\n",
      "4080/4080 [==============================] - 34s 8ms/step - loss: 0.0555 - categorical_accuracy: 0.9767 - val_loss: 0.1114 - val_categorical_accuracy: 0.9608\n",
      "Epoch 44/45\n",
      "4080/4080 [==============================] - 33s 8ms/step - loss: 0.0535 - categorical_accuracy: 0.9799 - val_loss: 0.1002 - val_categorical_accuracy: 0.9608\n",
      "Epoch 45/45\n",
      "4080/4080 [==============================] - 33s 8ms/step - loss: 0.0486 - categorical_accuracy: 0.9824 - val_loss: 0.1052 - val_categorical_accuracy: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbcb310d68>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=80,epochs=45,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[297,   0,   0],\n",
       "       [  5, 290,  12],\n",
       "       [  5,  16, 275]], dtype=int64)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "matrix = metrics.confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score = metrics.f1_score(Y_test.argmax(axis=1), Y_pred.argmax(axis=1), average = 'macro')\n",
    "accuracy = metrics.accuracy_score(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "precision = metrics.precision_score(Y_test.argmax(axis=1), Y_pred.argmax(axis=1), average = 'macro')\n",
    "recall = metrics.recall_score(Y_test.argmax(axis=1), Y_pred.argmax(axis=1), average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.96, the precision is 0.96, the recall is 0.96 and the f1 score is 0.96.\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is ' + str((\"%.2f\" % accuracy)) + ', the precision is ' + str((\"%.2f\" % precision)) + ', the recall is ' + str((\"%.2f\" % precision)) + ' and the f1 score is ' + str((\"%.2f\" % f1_score)) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
